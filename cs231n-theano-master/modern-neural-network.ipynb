{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 2: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (3073, 49000)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (3073, 1000)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (3073, 1000)\n",
      "Test labels shape:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000):\n",
    "  \"\"\"\n",
    "  Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "  it for the linear classifier. These are the same steps as we used for the\n",
    "  SVM, but condensed to a single function.  \n",
    "  \"\"\"\n",
    "  # Load the raw CIFAR-10 data\n",
    "  cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "  X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "  \n",
    "  # subsample the data\n",
    "  mask = range(num_training, num_training + num_validation)\n",
    "  X_val = X_train[mask]\n",
    "  y_val = y_train[mask]\n",
    "  mask = range(num_training)\n",
    "  X_train = X_train[mask]\n",
    "  y_train = y_train[mask]\n",
    "  mask = range(num_test)\n",
    "  X_test = X_test[mask]\n",
    "  y_test = y_test[mask]\n",
    "  \n",
    "  # Preprocessing: reshape the image data into rows\n",
    "  X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "  X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "  X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "  \n",
    "  # Normalize the data: subtract the mean image\n",
    "  mean_image = np.mean(X_train, axis = 0)\n",
    "  X_train -= mean_image\n",
    "  X_val -= mean_image\n",
    "  X_test -= mean_image\n",
    "  \n",
    "  # add bias dimension and transform into columns\n",
    "  X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))]).T\n",
    "  X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))]).T\n",
    "  X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))]).T\n",
    "  \n",
    "  return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()\n",
    "print 'Train data shape: ', X_train.shape\n",
    "print 'Train labels shape: ', y_train.shape\n",
    "print 'Validation data shape: ', X_val.shape\n",
    "print 'Validation labels shape: ', y_val.shape\n",
    "print 'Test data shape: ', X_test.shape\n",
    "print 'Test labels shape: ', y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def one_hot(x,n):\n",
    "    if type(x) == list: x = np.array(x)\n",
    "    x = x.flatten()\n",
    "    o_h = np.zeros((len(x),n))\n",
    "    o_h[np.arange(len(x)),x] = 1\n",
    "    return o_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels shape:  (49000, 10)\n",
      "Train labels shape:  (1000, 10)\n",
      "Train labels shape:  (1000, 10)\n",
      "Train data shape:  (49000, 3073)\n",
      "Validation data shape:  (1000, 3073)\n",
      "Test data shape:  (1000, 3073)\n"
     ]
    }
   ],
   "source": [
    "y_train_o_h = one_hot(y_train,10)\n",
    "y_val_o_h = one_hot(y_val,10)\n",
    "y_test_o_h = one_hot(y_test,10)\n",
    "print 'Train labels shape: ', y_train_o_h.shape\n",
    "print 'Train labels shape: ', y_val_o_h.shape\n",
    "print 'Train labels shape: ', y_test_o_h.shape\n",
    "\n",
    "X_train_t = np.transpose(X_train)\n",
    "X_val_t = np.transpose(X_val)\n",
    "X_test_t = np.transpose(X_test)\n",
    "print 'Train data shape: ', X_train_t.shape\n",
    "print 'Validation data shape: ', X_val_t.shape\n",
    "print 'Test data shape: ', X_test_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "srng = RandomStreams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def init_weights(shape, factor=0.00005):\n",
    "    return theano.shared(floatX(np.random.randn(*shape) * factor))\n",
    "\n",
    "def rectify(X):\n",
    "    return T.maximum(X, 0.0)\n",
    "\n",
    "def softmax(X):\n",
    "    e_x = T.exp(X - X.max(axis=1).dimshuffle(0, 'x'))\n",
    "    return e_x / e_x.sum(axis=1).dimshuffle(0, 'x')\n",
    "\n",
    "def RMSprop(cost, params, lr=0.001, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        acc = theano.shared(p.get_value() * 0.0)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        updates.append((p, p - lr * g))\n",
    "    return updates\n",
    "\n",
    "def dropout(X, p=0.0):\n",
    "    if p > 0:\n",
    "        retain_prob = 1 - p\n",
    "        X *= srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
    "        X /= retain_prob\n",
    "    return X\n",
    "\n",
    "def model(X, w_h, w_h2, w_o, p_drop_input, p_drop_hidden):\n",
    "    X = dropout(X, p_drop_input)\n",
    "    h = rectify(T.dot(X, w_h))\n",
    "\n",
    "    h = dropout(h, p_drop_hidden)\n",
    "    h2 = rectify(T.dot(h, w_h2))\n",
    "\n",
    "    h2 = dropout(h2, p_drop_hidden)\n",
    "    py_x = softmax(T.dot(h2, w_o))\n",
    "    return h, h2, py_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = T.fmatrix()\n",
    "Y = T.fmatrix()\n",
    "\n",
    "w_h = init_weights((3073, 500))\n",
    "w_h2 = init_weights((500, 500))\n",
    "w_o = init_weights((500, 10))\n",
    "\n",
    "noise_h, noise_h2, noise_py_x = model(X, w_h, w_h2, w_o, 0.2, 0.5)\n",
    "h, h2, py_x = model(X, w_h, w_h2, w_o, 0.0, 0.0)\n",
    "y_pred = T.argmax(py_x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost = T.mean(T.nnet.categorical_crossentropy(noise_py_x, Y))\n",
    "params = [w_h, w_h2, w_o]\n",
    "updates = RMSprop(cost, params, lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
    "# This may take a minute or two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Error: 0.574\n",
      "0 0.576\n",
      "1 0.575\n",
      "2 0.588\n",
      "3 0.587\n",
      "4 0.578\n",
      "5 0.585\n",
      "6 0.579\n",
      "7 0.58\n",
      "8 0.57\n",
      "9 0.582\n",
      "10 0.589\n",
      "11 0.583\n",
      "12 0.584\n",
      "13 0.576\n",
      "14 0.583\n",
      "15 0.574\n",
      "16 0.583\n",
      "17 0.584\n",
      "18 0.58\n",
      "19 0.578\n",
      "20 0.58\n",
      "21 0.584\n",
      "22 0.578\n",
      "23 0.579\n",
      "24 0.586\n",
      "25 0.576\n",
      "26 0.576\n",
      "27 0.574\n",
      "28 0.574\n",
      "29 0.584\n",
      "30 0.583\n",
      "31 0.586\n",
      "32 0.579\n",
      "33 0.577\n",
      "34 0.575\n",
      "35 0.581\n",
      "36 0.579\n",
      "37 0.577\n",
      "38 0.577\n",
      "39 0.579\n",
      "40 0.588\n",
      "41 0.574\n",
      "42 0.577\n",
      "43 0.585\n",
      "44 0.584\n",
      "45 0.587\n",
      "46 0.592\n",
      "47 0.575\n",
      "48 0.572\n",
      "49 0.583\n",
      "50 0.568\n",
      "51 0.583\n",
      "52 0.587\n",
      "53 0.578\n",
      "54 0.574\n",
      "55 0.581\n",
      "56 0.589\n",
      "57 0.57\n",
      "58 0.583\n",
      "59 0.581\n",
      "60 0.581\n",
      "61 0.589\n",
      "62 0.585\n",
      "63 0.578\n",
      "64 0.586\n",
      "65 0.585\n",
      "66 0.586\n",
      "67 0.575\n",
      "68 0.591\n",
      "69 0.585\n",
      "70 0.588\n",
      "71 0.592\n",
      "72 0.589\n",
      "73 0.589\n",
      "74 0.579\n",
      "75 0.578\n",
      "76 0.593\n",
      "77 0.588\n",
      "78 0.581\n",
      "79 0.589\n",
      "80 0.576\n",
      "81 0.583\n",
      "82 0.585\n",
      "83 0.586\n",
      "84 0.584\n",
      "85 0.57\n",
      "86 0.578\n",
      "87 0.584\n",
      "88 0.579\n",
      "89 0.589\n",
      "90 0.582\n",
      "91 0.587\n",
      "92 0.578\n",
      "93 0.592\n",
      "94 0.583\n",
      "95 0.583\n",
      "96 0.585\n",
      "97 0.581\n",
      "98 0.584\n",
      "99 0.57\n"
     ]
    }
   ],
   "source": [
    "print \"Initial Error:\", np.mean(np.argmax(y_val_o_h, axis=1) == predict(X_val_t))\n",
    "for i in range(100):\n",
    "    for start, end in zip(range(0, len(X_train_t), 128), range(128, len(X_train_t), 128)):\n",
    "        cost = train(X_train_t[start:end], y_train_o_h[start:end])\n",
    "    print i, np.mean(np.argmax(y_val_o_h, axis=1) == predict(X_val_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58099999999999996"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.argmax(y_test_o_h, axis=1) == predict(X_test_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
